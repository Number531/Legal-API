# REMEDIATION DISPATCH

**Diagnostic ID**: qa-diagnostic-2026-01-23
**Session ID**: 2026-01-22-1737576000
**Diagnostic Score**: **82.4%**
**Remediation Tier**: **TIER 3 — FULL**
**Total Issues Found**: 9
**Issues In Scope**: 9 (4 CRITICAL + 1 HIGH + 4 MEDIUM + 0 LOW)
**Estimated Duration**: 29-41 hours
**Max Cycles**: 2
**Current Cycle**: 1
**Target Score**: ≥93% (CERTIFY threshold)

---

## WAVE 1: Additional Research
- **Parallel**: N/A (no tasks)
- **Gate**: none
- **Duration**: 0 hours

**No research tasks required.** All substantive analysis complete (1,423 footnotes, comprehensive quantification, draft contract provisions present). Remediation focuses on structural reorganization.

---

## WAVE 2: Content Additions
- **Parallel**: YES
- **Gate**: none (immediate start)
- **Duration**: 6-8 hours

| Task ID | Agent | Priority | Est. Minutes | Target Section | Description | Output File | Success Criteria |
|---------|-------|----------|--------------|----------------|-------------|-------------|------------------|
| **W2-001** | memo-executive-summary-writer | **CRITICAL** | 240-300 | Insert new Section II | **Generate Questions Presented Section (Under/Does/When Format)**<br><br>**Input**: Read final-memorandum.md Section I.B "BRIEF ANSWERS TO QUESTIONS PRESENTED" table (lines 225-239). Extract 12 abbreviated questions from "Question (Abbreviated)" column.<br><br>**Task**: Expand each abbreviated question to full Under/Does/When format:<br>- **Format**: "Under [specific statute/regulation], does [specific conduct] [specific legal consequence] when [critical facts from transaction]?"<br>- **Order**: By deal-blocking risk (CRITICAL findings first: Valuation Markdown, Key Person, MFN Side Letter, PM Retention; then HIGH findings; then MEDIUM)<br>- **Specificity**: Incorporate specific facts (e.g., "when 8 cross-trades totaling $7M-$17M occurred during 2021-2023 without advance client consent")<br>- **Mapping**: Cross-reference each question to analysis section (IV.A through IV.L)<br><br>**Example Transformation**:<br>- Abbreviated: "Advisers Act compliance?"<br>- Full: "Under Investment Advisers Act Section 206(4) and Rule 206(4)-2 (Custody Rule), does Pinnacle's failure to obtain surprise audits by an independent accountant constitute a custody rule violation when Pinnacle serves as general partner of 8 hedge funds holding $18.7 billion in combined assets and deemed to have custody under Rule 206(4)-2(a)(3)?"<br><br>**Output Structure**:<br>```markdown<br>## II. QUESTIONS PRESENTED<br><br>1. [Under/Does/When question for CRITICAL finding #1]<br><br>2. [Under/Does/When question for CRITICAL finding #2]<br><br>...<br><br>12. [Under/Does/When question for last finding]<br>```<br><br>**Data Sources**: Section I.B table, Section IV.A-IV.L analysis sections for specific facts | remediation-outputs/W2-001-questions-presented.md | - 12 questions in Under/Does/When format<br>- Questions ordered by severity (CRITICAL → HIGH → MEDIUM)<br>- Each question incorporates ≥3 specific transaction facts<br>- Each question mapped to analysis section (IV.A-IV.L)<br>- Questions answerable Yes/No/Probably Yes/Probably No |
| **W2-002** | memo-executive-summary-writer | **HIGH** | 120-180 | Insert new Section III | **Generate Brief Answers Section (Narrative Format)**<br><br>**Input**: Read final-memorandum.md Section I.B table (lines 225-239). Extract data from "Answer" and "Rationale" columns.<br><br>**Task**: For each of 12 questions, generate full narrative Brief Answer:<br>- **Definitive Answer**: Start with "**Probably Yes.**" or "**Probably No.**" or "**Yes.**" or "**No.**" (use hedged "Probably" when probability 40-80%, definitive when >80% or <20%)<br>- **Because Clause**: Follow with "Because [2-3 sentence reasoning]"<br>- **Rule Reference**: Cite key statute/regulation/case controlling the analysis<br>- **Critical Facts**: Incorporate 2-3 critical facts from transaction<br>- **Section Cross-Reference**: End with "See Section IV.X for detailed analysis."<br><br>**Example Brief Answer**:<br>"**Probably Yes.** Because Pinnacle failed to obtain surprise audits by an independent accountant as required by Rule 206(4)-2(b)(4) for advisers with custody, and the October 2023 SEC examination documented this deficiency across all 8 hedge funds. The Custody Rule mandates annual surprise examinations when an adviser is deemed to have custody by virtue of serving as general partner of a limited partnership, and Pinnacle's failure exposes it to civil penalties of $50,000-$100,000 based on precedent enforcement actions (*In re First Eagle Investment Management*, SEC Release No. IA-5474). See Section IV.A.B.1 for detailed analysis."<br><br>**Output Structure**:<br>```markdown<br>## III. BRIEF ANSWERS<br><br>### 1. [Brief restatement of Question 1]<br><br>[Full narrative answer]<br><br>### 2. [Brief restatement of Question 2]<br><br>[Full narrative answer]<br><br>...<br>```<br><br>**Data Sources**: Section I.B table, W2-001 questions, Section IV.A-IV.L analysis sections | remediation-outputs/W2-002-brief-answers.md | - 12 narrative Brief Answers<br>- Each includes definitive answer (Yes/No/Probably)<br>- Each includes "because" clause with 2-3 sentence reasoning<br>- Each cites key rule/precedent<br>- Each incorporates critical facts<br>- Each cross-references to detailed analysis section<br>- Answers align with probability assessments in Section II Aggregate Risk Summary |

---

## WAVE 3: Structural Fixes (HYBRID WORKFLOW)
- **Parallel**: YES (within each P group)
- **Gate**: WAVE 2 complete
- **Duration**: 12-16 hours

**HYBRID WORKFLOW**: Python scripts perform mechanical operations (header insertion, dependency scanning), then agents perform semantic validation and content generation.

### P1: CREAC Headers (CRITICAL Priority)

| Task ID | Agent/Script | Priority | Est. Minutes | Target Section | Description | Output File | Success Criteria |
|---------|--------------|----------|--------------|----------------|-------------|-------------|------------------|
| **W3-001-SCAN** | apply-creac-headers.py | **CRITICAL** | 60 | All IV.A-IV.L | **SCRIPT: Scan and Map CREAC Insertion Points**<br><br>**Input**: final-memorandum.md<br><br>**Algorithm**:<br>1. Locate all analysis subsections (pattern: `### B\.\d+` or `### B\. [Title]`)<br>2. For each subsection, detect CREAC components:<br>   - **Conclusion**: First paragraph containing definitive statement ("Pinnacle faces...", "The transaction creates...")<br>   - **Rule**: Paragraphs citing primary authority (USC citations, CFR citations, case names in italics)<br>   - **Explanation**: Paragraphs discussing case precedents (pattern: *Case Name v. Case Name* followed by holdings)<br>   - **Application**: Paragraphs comparing transaction facts to precedent (pattern: "Pinnacle's situation is analogous...", "Here, the facts show...")<br>3. Generate CREAC-insertion-map.json:<br>```json<br>{<br>  "section_id": "IV.A.B.1",<br>  "title": "SEC October 2023 Examination Deficiencies",<br>  "creac_map": {<br>    "conclusion": { "line_start": 820, "line_end": 825, "insert_header_before": 820 },<br>    "rule": { "line_start": 826, "line_end": 835, "insert_header_before": 826 },<br>    "explanation": { "line_start": 836, "line_end": 860, "insert_header_before": 836 },<br>    "application": { "line_start": 861, "line_end": 890, "insert_header_before": 861 }<br>  }<br>}<br>```<br><br>**Output**: CREAC-insertion-map.json with insertion points for ~36 subsections (12 sections × 3 findings avg) | scripts/CREAC-insertion-map.json | - JSON file with 36+ section entries<br>- Each entry maps Conclusion/Rule/Explanation/Application line ranges<br>- Insertion points identified for header placement |
| **W3-001-INSERT** | apply-creac-headers.py | **CRITICAL** | 120 | All IV.A-IV.L | **SCRIPT: Insert CREAC Headers**<br><br>**Input**: final-memorandum.md, CREAC-insertion-map.json<br><br>**Task**: For each subsection in CREAC-insertion-map.json:<br>1. Insert `#### Conclusion` header before conclusion paragraph<br>2. Insert `#### Rule` header before rule paragraph<br>3. Insert `#### Explanation` header before explanation paragraph<br>4. Insert `#### Application` header before application paragraph<br>5. **DO NOT insert `#### Counter-Analysis` headers** (P3 consolidation required first)<br>6. Preserve all existing content (only add headers, no deletions)<br><br>**Example Output**:<br>```markdown<br>### B.1 SEC October 2023 Examination Deficiencies<br><br>#### Conclusion<br><br>Pinnacle faces civil penalties of $150K-$260K and ongoing remediation costs with NPV of $5.625M...<br><br>#### Rule<br><br>Rule 206(4)-2 under the Investment Advisers Act, known as the Custody Rule, establishes safeguards...<br><br>#### Explanation<br><br>In *First Eagle Investment Management*, the SEC assessed penalties...<br><br>#### Application<br><br>Pinnacle's situation is analogous to *First Eagle*. Here, Pinnacle serves as general partner...<br>```<br><br>**Output**: final-memorandum-creac-headers.md | final-memorandum-creac-headers.md | - 36+ subsections with CREAC headers inserted<br>- Headers in order: Conclusion (first), Rule, Explanation, Application<br>- All existing content preserved<br>- No Counter-Analysis headers yet (P3) |
| **W3-001-VALIDATE** | memo-remediation-writer | **CRITICAL** | 180-240 | All IV.A-IV.L | **AGENT: Validate CREAC Header Placement**<br><br>**Input**: final-memorandum-creac-headers.md<br><br>**Task**: For each of 36+ CREAC structures, verify:<br>1. **Conclusion First**: `#### Conclusion` appears BEFORE `#### Rule`. Conclusion contains definitive conclusion statement ("Pinnacle faces...", "The risk is..."). If conclusion appears under wrong header (e.g., under `#### Rule`), manually relocate content.<br>2. **Rule Cites Primary Authority**: `#### Rule` section cites statutes (15 U.S.C. §), regulations (17 C.F.R. §), or cases (*Name v. Name*). If rule section contains only policy discussion or secondary sources, flag for revision.<br>3. **Explanation Discusses Cases Only**: `#### Explanation` section discusses analogous precedents (case facts, holdings, rationales). If Explanation contains Pinnacle's facts (client facts), flag for relocation to Application.<br>4. **Application Compares Facts**: `#### Application` section compares Pinnacle's facts to precedent facts using fact-to-fact analysis ("Pinnacle's [fact X] is analogous to [case name]'s [fact Y]"). If Application merely restates conclusion without comparison, flag for revision.<br>5. **Generate Validation Report**: Document any misplacements, missing components, or content relocations needed.<br><br>**Corrections**: If header placement is incorrect (script misidentified CREAC components), manually relocate content to correct header in final-memorandum-creac-validated.md.<br><br>**Output**: remediation-outputs/W3-001-creac-validation-report.md + final-memorandum-creac-validated.md (with manual corrections applied) | remediation-outputs/W3-001-creac-validation-report.md<br>+<br>final-memorandum-creac-validated.md | - Validation report shows ≥95% header placement accuracy<br>- All misplaced content relocated to correct CREAC component<br>- Zero client facts in Explanation sections<br>- All Conclusion headers appear first in subsection<br>- final-memorandum-creac-validated.md ready for P2 cross-reference insertion |

---

### P2: Cross-References (CRITICAL Priority)

| Task ID | Agent/Script | Priority | Est. Minutes | Target Section | Description | Output File | Success Criteria |
|---------|--------------|----------|--------------|----------------|-------------|-------------|------------------|
| **W3-XREF-SCAN** | analyze-xrefs.py | **CRITICAL** | 120 | All IV.A-IV.L | **SCRIPT: Build Cross-Reference Dependency Graph**<br><br>**Input**: final-memorandum-creac-validated.md<br><br>**Algorithm**:<br>1. Extract all findings with severity ratings (CRITICAL/HIGH/MEDIUM) from risk assessment tables<br>2. For each finding, identify multi-domain implications:<br>   - **MFN Side Letter** (IV.D): Impacts IV.H (client concentration - Plan A termination risk), IV.F (marketing disclosure)<br>   - **ERISA Cross-Trading** (IV.C): Relates to IV.A (Advisers Act disclosure), IV.E (SEC enforcement)<br>   - **Valuation Markdown** (IV.G): Affects IV.J (earnout structure), IV.D (LP disputes), IV.I (PM retention via earnout)<br>   - **Key Person Redemption** (IV.D): Impacts IV.H (client retention), IV.I (PM retention strategy)<br>   - **Revenue Sharing** (IV.A): Relates to IV.C (ERISA prohibited transactions), IV.F (marketing disclosure)<br>3. Search for existing inline cross-references (pattern: `See Section IV\.[A-L]`, `supra`, `infra`)<br>4. Identify "orphaned findings" (multi-domain findings with zero inline cross-references)<br>5. Generate xref-matrix.json:<br>```json<br>{<br>  "finding_id": "IV.D.B.2",<br>  "title": "MFN Side Letter Ongoing Costs",<br>  "section": "IV.D",<br>  "related_sections": ["IV.H", "IV.F"],<br>  "orphan_status": true,<br>  "recommended_xrefs": [<br>    {<br>      "insert_location": "IV.D.B.2 Application section, after paragraph discussing ongoing fee differential",<br>      "xref_text": "See Section IV.H.B.1 for analysis of MFN side letter impact on Plan A client concentration risk, where Plan A's MFN clause creates perpetual fee reduction exposure of $3.6M annually ($98M NPV)."<br>    },<br>    {<br>      "insert_location": "IV.H.B.1 Application section, after paragraph discussing Plan A termination triggers",<br>      "xref_text": "See Section IV.D.B.2 for detailed analysis of MFN side letter terms and Delaware contract law enforceability."<br>    }<br>  ]<br>}<br>```<br><br>**Target**: Identify 100+ recommended cross-references across 18 orphaned findings<br><br>**Output**: scripts/xref-matrix.json + scripts/xref-orphans-report.md (summary of orphaned findings) | scripts/xref-matrix.json<br>+<br>scripts/xref-orphans-report.md | - xref-matrix.json contains 100+ recommended cross-references<br>- All CRITICAL/HIGH findings analyzed for multi-domain implications<br>- Orphan report identifies findings lacking inline cross-references<br>- Recommended xref text provides specific section + implication detail |
| **W3-XREF-INSERT-IV-A** | xref-insertion-agent | **CRITICAL** | 60 | Section IV.A | **AGENT: Insert Cross-References for Section IV.A**<br><br>**Input**: final-memorandum-creac-validated.md, xref-matrix.json (filter: section == "IV.A" OR related_sections contains "IV.A")<br><br>**Task**: For each recommended cross-reference involving Section IV.A:<br>1. Locate insertion point (typically end of Application section for finding)<br>2. Insert cross-reference sentence in format: "See Section IV.X.Y for [specific implication]."<br>3. Ensure cross-reference is **semantic** (explains WHY sections relate, not just "See IV.X")<br>4. Preserve existing content (append cross-references, don't delete)<br><br>**Example Insertions**:<br>- In IV.A.B.3 (Revenue Sharing Conflicts), after Application section:<br>  "See Section IV.C.B.2 for ERISA prohibited transaction analysis of revenue sharing arrangements with plan clients, where 12b-1 fees and solicitor payments to broker-dealers recommending Pinnacle funds to ERISA plans may constitute indirect compensation triggering PTE 77-4 compliance requirements."<br><br>- In IV.A.B.2 (Marketing Rule Violations), after Application section:<br>  "See Section IV.F.B.1 for analysis of testimonial disclosure requirements under Rule 206(4)-1(b)(1), where fee reductions granted to testifying clients create conflicts requiring prominent disclosure."<br><br>**Output**: remediation-outputs/W3-XREF-IV-A.md (Section IV.A with cross-references inserted) | remediation-outputs/W3-XREF-IV-A.md | - 8-12 cross-references inserted in Section IV.A<br>- All cross-references semantic (explain implication, not generic)<br>- Cross-references placed at logical points (end of Application sections)<br>- Existing content preserved |
| **W3-XREF-INSERT-IV-B** through **W3-XREF-INSERT-IV-L** | xref-insertion-agent | **CRITICAL** | 60 each (11 sections × 60 min = 660 min total) | Sections IV.B through IV.L | **AGENT: Insert Cross-References for Remaining Sections**<br><br>**Input**: final-memorandum-creac-validated.md, xref-matrix.json (filter by section)<br><br>**Task**: Repeat cross-reference insertion for each remaining section:<br>- IV.B: Investment Company Act (cross-refs to IV.A shareholder approval, IV.D fund governance)<br>- IV.C: ERISA (cross-refs to IV.A revenue sharing, IV.H client concentration)<br>- IV.D: Private Funds (cross-refs to IV.H key person/MFN, IV.G valuation/LP disputes, IV.I PM retention)<br>- IV.E: SEC Enforcement (cross-refs to IV.A examination deficiencies, IV.G valuation)<br>- IV.F: Marketing Rule (cross-refs to IV.A testimonials/revenue sharing, IV.D performance advertising)<br>- IV.G: Valuation (cross-refs to IV.D LP disputes, IV.J earnout, IV.I PM retention earnout)<br>- IV.H: Commercial Contracts (cross-refs to IV.D MFN/key person, IV.I PM retention)<br>- IV.I: Employment (cross-refs to IV.H client retention, IV.G earnout valuation, IV.J earnout tax)<br>- IV.J: Tax (cross-refs to IV.G valuation/earnout, IV.I earnout structure)<br>- IV.K: Cybersecurity (cross-refs to IV.L cyber insurance, IV.A Regulation S-P compliance)<br>- IV.L: Insurance (cross-refs to IV.K cyber risk, IV.C ERISA fiduciary coverage)<br><br>**Parallelization**: All 11 tasks (W3-XREF-INSERT-IV-B through IV-L) can run in parallel (independent section edits)<br><br>**Output**: remediation-outputs/W3-XREF-IV-[B-L].md (11 files) | remediation-outputs/W3-XREF-IV-B.md through W3-XREF-IV-L.md (11 files) | - 100+ total cross-references inserted across all 12 sections<br>- Each section has 8-12 cross-references<br>- All orphaned findings connected to related sections<br>- xref-matrix.json shows orphan_status: false for 95%+ findings |

---

### P3: Counter-Analysis Consolidation (MEDIUM Priority)

| Task ID | Agent/Script | Priority | Est. Minutes | Target Section | Description | Output File | Success Criteria |
|---------|--------------|----------|--------------|----------------|-------------|-------------|------------------|
| **W3-COUNTER-SCAN** | detect-counter-analysis.py | **MEDIUM** | 120 | All IV.A-IV.L | **SCRIPT: Detect Scattered Counter-Analysis**<br><br>**Input**: final-memorandum-creac-validated.md (with CREAC headers + cross-references)<br><br>**Algorithm**:<br>1. Search for counter-analysis patterns:<br>   - Keywords: "Counter-Analysis", "Alternative View", "Counterargument", "Opposing View", "However", "Conversely", "Nonetheless", "Sellers could argue", "Opposing counsel may contend", "Pinnacle could assert", "A contrary interpretation"<br>2. For each instance, extract:<br>   - section_id (e.g., "IV.A.B.1")<br>   - finding_id (e.g., "SEC October 2023 Examination Deficiencies")<br>   - counter_text (paragraph containing counter-analysis)<br>   - current_location (Explanation / Application / other)<br>   - line_number<br>3. Generate counter-analysis-locations.json + per-section JSON files (counter-analysis-locations-IV-A.json through counter-analysis-locations-IV-L.json)<br><br>**Example JSON**:<br>```json<br>{<br>  "section_id": "IV.A.B.1",<br>  "finding_id": "SEC October 2023 Examination Deficiencies",<br>  "instances": [<br>    {<br>      "line_number": 912,<br>      "current_location": "Application",<br>      "counter_text": "Sellers could argue that remediation was already underway pre-closing, mitigating penalties...",<br>      "action": "relocate_to_counter_analysis_header"<br>    }<br>  ]<br>}<br>```<br><br>**Target**: Identify 48 scattered counter-analysis instances (per diagnostic finding)<br><br>**Output**: scripts/counter-analysis-locations.json + scripts/counter-analysis-locations-IV-*.json (12 files) | scripts/counter-analysis-locations.json<br>+<br>scripts/counter-analysis-locations-IV-A.json through IV-L.json (12 files) | - 48+ counter-analysis instances detected<br>- All instances mapped to section/finding/line number<br>- Per-section JSON files enable parallel consolidation in W3-COUNTER tasks |
| **W3-COUNTER-IV-A** | memo-remediation-writer | **MEDIUM** | 60 | Section IV.A | **AGENT: Consolidate Counter-Analysis for Section IV.A**<br><br>**Input**: final-memorandum-creac-validated.md (with CREAC headers + cross-refs), counter-analysis-locations-IV-A.json<br><br>**Task**: For each finding in Section IV.A (B.1, B.2, B.3):<br>1. Read counter-analysis-locations-IV-A.json to find all counter-analysis instances for that finding<br>2. Extract counter-text from current locations (Explanation/Application sections)<br>3. Insert new `#### Counter-Analysis` header after `#### Application` section<br>4. Consolidate all counter-text under `#### Counter-Analysis` header<br>5. Organize counter-analysis to address:<br>   - Opposing legal interpretations (e.g., "Sellers may argue the Custody Rule surprise exam requirement does not apply to...")<br>   - Mitigating facts favoring Seller (e.g., "Remediation was underway pre-closing, reducing penalty exposure...")<br>   - Rebuttal to counter-arguments (e.g., "However, SEC precedent in *First Eagle* shows no mitigation credit for post-deficiency remediation...")<br>6. Remove scattered counter-text from Explanation/Application sections (avoid duplication)<br>7. Ensure counter-analysis is substantive (≥2 paragraphs per finding, not perfunctory)<br><br>**Example Output**:<br>```markdown<br>### B.1 SEC October 2023 Examination Deficiencies<br><br>#### Conclusion<br>[existing text]<br><br>#### Rule<br>[existing text]<br><br>#### Explanation<br>[existing text, with scattered counter-arguments removed]<br><br>#### Application<br>[existing text, with scattered counter-arguments removed]<br><br>#### Counter-Analysis<br><br>Sellers could argue that the Custody Rule surprise exam requirement should not result in penalties because Pinnacle engaged Deloitte to perform retroactive surprise exams immediately upon discovering the deficiency in October 2023, demonstrating good faith remediation efforts. Additionally, Sellers may contend that no client funds were actually misappropriated, and the violation was purely technical without investor harm.<br><br>However, SEC precedent does not support mitigation based on post-deficiency remediation. In *First Eagle Investment Management*, the SEC assessed full penalties despite the adviser's immediate corrective action, reasoning that the Custody Rule serves prophylactic purposes and penalties are warranted regardless of actual investor harm. Moreover, the "technical" nature of the violation does not reduce exposure—the SEC has consistently held that strict compliance with custody safeguards is non-negotiable for advisers deemed to have custody.<br><br>The primary risk remains civil penalties of $150K-$260K based on precedent settlements, with limited opportunity for mitigation arguments to reduce exposure below the low end of this range.<br>```<br><br>**Output**: remediation-outputs/W3-COUNTER-IV-A.md | remediation-outputs/W3-COUNTER-IV-A.md | - 3+ `#### Counter-Analysis` headers inserted (one per finding in IV.A)<br>- All scattered counter-analysis from IV.A consolidated under headers<br>- Counter-analysis addresses opposing interpretations + mitigating facts + rebuttals<br>- Substantive content (≥2 paragraphs per finding)<br>- No duplication (scattered counter-text removed from Explanation/Application) |
| **W3-COUNTER-IV-B** through **W3-COUNTER-IV-L** | memo-remediation-writer | **MEDIUM** | 60 each (11 sections × 60 min = 660 min total) | Sections IV.B through IV.L | **AGENT: Consolidate Counter-Analysis for Remaining Sections**<br><br>**Input**: final-memorandum-creac-validated.md (with CREAC headers + cross-refs), counter-analysis-locations-IV-[X].json<br><br>**Task**: Repeat counter-analysis consolidation for each remaining section using same methodology as W3-COUNTER-IV-A.<br><br>**Parallelization**: All 11 tasks (W3-COUNTER-IV-B through IV-L) can run in parallel (independent section edits)<br><br>**Output**: remediation-outputs/W3-COUNTER-IV-[B-L].md (11 files) | remediation-outputs/W3-COUNTER-IV-B.md through W3-COUNTER-IV-L.md (11 files) | - 36+ total `#### Counter-Analysis` headers inserted (3 findings × 12 sections)<br>- All 48 scattered counter-analysis instances consolidated<br>- Each Counter-Analysis section substantive (≥2 paragraphs)<br>- Counter-analysis addresses opposing views + mitigation + rebuttals |

---

## WAVE 4: Language/Format Fixes
- **Parallel**: YES
- **Gate**: WAVE 3 complete
- **Duration**: 4-6 hours

| Task ID | Agent | Priority | Est. Minutes | Target Sections | Description | Output File | Success Criteria |
|---------|-------|----------|--------------|----------------|-------------|-------------|------------------|
| **W4-001** | memo-remediation-writer | **MEDIUM** | 120 | All sections | **Neutralize Advocacy Language**<br><br>**Input**: final-memorandum-creac-validated.md (with Wave 3 edits)<br><br>**Task**: Search for 9 instances of advocacy language and replace with neutral phrasing:<br>1. "clearly" (3 instances) → Replace with: "based on precedent" / "the statute provides" / omit<br>2. "obviously" (2 instances) → Omit or replace with: "the regulation specifies"<br>3. "undoubtedly" (2 instances) → Replace with: "the majority rule holds" / "courts have consistently held"<br>4. "without question" (1 instance) → Replace with: "consistently"<br>5. "it is certain" (1 instance) → Replace with: "it is probable" / "precedent suggests"<br><br>**Preserve Context**: Do not alter surrounding sentences. Only replace advocacy term, leaving rest of paragraph unchanged.<br><br>**Output**: remediation-outputs/W4-001-neutral-language.md (marked-up document showing replacements) | remediation-outputs/W4-001-neutral-language.md | - Zero advocacy language instances remaining<br>- Replacement language neutral and accurate<br>- Surrounding context preserved |
| **W4-002** | memo-executive-summary-writer | **MEDIUM** | 180-240 | Section I (Executive Summary) | **Reduce Executive Summary to 3,000 Words**<br><br>**Input**: final-memorandum.md Section I (lines 175-734, currently ~4,200 words)<br><br>**Task**: Condense Executive Summary from 4,200 to 3,000 words (25% reduction) while preserving all critical content:<br>1. **Keep Unchanged**: Section I (Transaction Recommendation), I.B (Brief Answers table) — **DO NOT edit these**<br>2. **Consolidate Section II (Aggregate Risk Summary)**: Keep Risk Summary Table intact (lines 244-267), but reduce prose explanation (lines 269-370) from ~750 words to ~400 words. Focus: Reduce repetitive explanations of NPV/DCF/EV methodology (state once, not per finding).<br>3. **Consolidate Section III (Critical Issues Matrix)**: Convert prose paragraphs to bullet list format. Preserve all 20 findings, but reduce description from 2-3 sentences to 1 sentence per finding.<br>4. **Consolidate Section IV (Cross-Domain Impact Analysis)**: Reduce from ~800 words to ~400 words. Keep all 12 cross-domain connections, but use bullet format instead of full paragraphs.<br>5. **Consolidate Section V (Negotiation Position Summary)**: Reduce from ~600 words to ~300 words. Keep all negotiation strategies, but condense from paragraph format to bullet/table format.<br>6. **Consolidate Section VI (Timeline & Critical Path)**: Keep timeline intact, reduce prose explanation.<br><br>**Preserve**: All dollar amounts, probabilities, severity ratings, recommendations, timelines. Focus reduction on prose explanations, not data.<br><br>**Target**: 3,000 words ±200 words acceptable<br><br>**Output**: remediation-outputs/W4-002-exec-summary-condensed.md | remediation-outputs/W4-002-exec-summary-condensed.md | - Executive Summary ≤3,200 words<br>- All critical numbers preserved (18 findings, dollar amounts, probabilities)<br>- All recommendations preserved<br>- Reduction achieved via format consolidation (prose → bullets/tables), not data deletion |
| **W4-003** | memo-remediation-writer | **LOW** | 60 | Throughout | **Add Precedent Transaction References to Draft Provisions**<br><br>**Input**: final-memorandum.md, identify draft contract provisions lacking precedent references (~30% of 24 provisions = 7 provisions)<br><br>**Task**: For each provision lacking precedent reference, add comparable transaction citation:<br>- **Format**: "[See comparable: *[Acquirer/Target]* [provision type], [deal characteristic]]"<br>- **Focus**: HIGH/CRITICAL finding provisions (MFN escrow, valuation markdown escrow, key person indemnity, ERISA VFCP representation)<br>- **Examples**:<br>  - Valuation markdown escrow → "[See comparable: *Blackstone/GCM Grosvenor* $50M valuation dispute escrow with independent audit condition]"<br>  - Key person indemnity → "[See comparable: *Ares/AMP Capital* key person redemption indemnity capped at $100M with LP consent mitigation]"<br>  - ERISA VFCP representation → "[See comparable: *Carlyle/NGP* ERISA compliance representation with DOL VFCP filing covenant]"<br><br>**Research Sources**: Use precedent transaction knowledge from 2018-2024 PE acquisitions of asset managers. If specific deal precedent unavailable, cite general market practice (e.g., "[Market practice: Valuation escrows typically 15-25% of purchase price with 18-36 month release]").<br><br>**Output**: remediation-outputs/W4-003-precedent-references.md | remediation-outputs/W4-003-precedent-references.md | - 7+ provisions updated with precedent references<br>- All HIGH/CRITICAL provisions include precedent<br>- Precedent citations specific (deal names) where available, general market practice otherwise |

---

## WAVE 5: Citation Cleanup
- **Parallel**: NO (sequential to avoid footnote renumbering conflicts)
- **Gate**: WAVE 4 complete
- **Duration**: 4-6 hours

| Task ID | Agent | Priority | Est. Minutes | Target | Description | Output File | Success Criteria |
|---------|-------|----------|--------------|--------|-------------|-------------|------------------|
| **W5-001** | citation-validator | **MEDIUM** | 180-240 | Top 100 material citations | **Add Pincites to Top 100 Citations**<br><br>**Input**: final-memorandum.md CONSOLIDATED FOOTNOTES section (lines 13528+), 1,423 footnotes total, 251 currently have pincites<br><br>**Prioritization**: Select top 100 citations based on:<br>1. **PRIMARY authority first**: Statutes (15 U.S.C. §, 26 U.S.C. §, 29 U.S.C. §), Regulations (17 C.F.R. §), SEC Releases (IA-series, IC-series), Court cases (Supreme Court, Circuit Courts)<br>2. **HIGH/CRITICAL findings first**: Citations supporting findings with HIGH or CRITICAL severity (MFN, Key Person, Valuation, PM Retention, ERISA, etc.)<br>3. **First-reference citations**: Full citations (not short-form "Id." or "*Case Name*, supra")<br><br>**Task**: For each selected citation:<br>1. If statute/regulation: Add specific subsection if not already present (e.g., "15 U.S.C. § 80b-6(4)" → "15 U.S.C. § 80b-6(4) (fiduciary duty provision)")<br>2. If SEC Release: Add specific paragraph or page (e.g., "SEC Release No. IA-5474 at 3-4" or "SEC Release No. IA-5474, ¶12")<br>3. If case: Add page number for specific proposition cited (e.g., "375 U.S. 180" → "375 U.S. 180, 194 (1963)")<br>4. If pincite unavailable: Add verification note in square brackets: "[full document at [EDGAR/CourtListener URL], specific provision discussed in Section [X]]"<br><br>**Format**: Bluebook 22nd Edition (maintain existing format, only add pincite)<br><br>**Target**: Increase pincite compliance from 17.6% (251/1,423) to 24.7% (351/1,423)<br><br>**Output**: remediation-outputs/W5-001-pincites.md (marked-up footnotes with pincites added) | remediation-outputs/W5-001-pincites.md | - 100 citations updated with pincites<br>- Pincite compliance: 351/1,423 = 24.7%<br>- Priority given to PRIMARY authority + HIGH/CRITICAL findings<br>- Bluebook format maintained |
| **W5-002** | citation-validator | **MEDIUM** | 120-180 | Top 50 case citations | **Add Explanatory Parentheticals to Case Citations**<br><br>**Input**: final-memorandum.md CONSOLIDATED FOOTNOTES section, identify top 50 case citations lacking explanatory parentheticals<br><br>**Prioritization**: Select cases where relevance is NOT obvious from context (exclude cases discussed extensively in Explanation sections where holding is already explained)<br><br>**Task**: For each selected case citation, add explanatory parenthetical:<br>- **Format**: "*(holding that [brief statement of relevant holding])*" or "*(finding [specific fact pattern] created fiduciary breach)*"<br>- **Brevity**: 10-15 words maximum<br>- **Relevance**: Explain WHY case is cited (specific holding relevant to analysis, not general case summary)<br><br>**Examples**:<br>- Before: "*In re First Eagle Investment Management, LLC*, SEC Release No. IA-5474 (July 9, 2020)."<br>- After: "*In re First Eagle Investment Management, LLC*, SEC Release No. IA-5474 (July 9, 2020) (assessing $200,000 penalty for custody rule violations despite immediate remediation)."<br><br>- Before: "*Vernazza v. SEC*, 327 F.3d 851 (D.C. Cir. 2003)."<br>- After: "*Vernazza v. SEC*, 327 F.3d 851 (D.C. Cir. 2003) (holding that general conflict warnings insufficient where adviser faces specific quantified conflicts)."<br><br>**Output**: remediation-outputs/W5-002-parentheticals.md | remediation-outputs/W5-002-parentheticals.md | - 50 case citations updated with explanatory parentheticals<br>- Parentheticals explain relevance (WHY cited)<br>- Brevity maintained (10-15 words)<br>- Focus on non-obvious relevance cases |

---

## WAVE 6: Final Assembly
- **Parallel**: NO (sequential integration)
- **Gate**: WAVE 5 complete
- **Duration**: 3-5 hours

| Task ID | Agent | Priority | Est. Minutes | Description | Output File | Success Criteria |
|---------|-------|----------|--------------|-------------|-------------|------------------|
| **W6-001** | memo-final-synthesis | **CRITICAL** | 180-300 | **Integrate All Remediation Outputs into final-memorandum-v2.md**<br><br>**Input**: final-memorandum.md + all remediation-outputs/*.md files from Waves 2-5<br><br>**Integration Sequence**:<br>1. **Insert W2-001 (Questions Presented)**: Insert as new Section II, immediately after current Section I.B (Brief Answers table)<br>2. **Insert W2-002 (Brief Answers)**: Insert as new Section III, immediately after new Section II (Questions Presented)<br>3. **Renumber Existing Sections**: Current Section II "Aggregate Risk Summary" becomes new Section IV; current Section III "Critical Issues Matrix" becomes new Section V, etc. Update all section references in Table of Contents and cross-references.<br>4. **Integrate W3-001 CREAC Headers**: For all 12 analysis sections (IV.A-IV.L in NEW numbering, originally IV.A-IV.L), insert CREAC headers from final-memorandum-creac-validated.md<br>5. **Integrate W3-XREF Cross-References**: For each section IV.A-IV.L, merge cross-references from remediation-outputs/W3-XREF-IV-*.md<br>6. **Integrate W3-COUNTER Counter-Analysis**: For each section IV.A-IV.L, insert `#### Counter-Analysis` headers and consolidated content from remediation-outputs/W3-COUNTER-IV-*.md<br>7. **Apply W4-001 Neutral Language**: Replace advocacy language instances per remediation-outputs/W4-001-neutral-language.md<br>8. **Replace Executive Summary**: Replace current Section I (lines 175-734) with condensed version from remediation-outputs/W4-002-exec-summary-condensed.md<br>9. **Apply W4-003 Precedent References**: Insert precedent transaction citations into draft provisions per remediation-outputs/W4-003-precedent-references.md<br>10. **Update Footnotes**: Apply pincites from remediation-outputs/W5-001-pincites.md and parentheticals from remediation-outputs/W5-002-parentheticals.md to CONSOLIDATED FOOTNOTES section<br>11. **Regenerate Cross-Reference Matrix**: Update Section V (formerly Section V, new numbering TBD) Cross-Reference Matrix to reflect new section numbers and added cross-references from Wave 3<br>12. **Regenerate Table of Contents**: Update lines 21-170 to reflect new section structure (Sections II-III added, renumbering ripple effect)<br>13. **Add Document Footer**: Append "---\n\n**END OF MEMORANDUM**\n" at end of document<br>14. **Update Metadata Tables**: At end of each analysis section (IV.A-IV.L), update metadata rows for "Draft Provisions Generated", "Cross-References", "Footnotes" to reflect Wave 3-5 additions<br>15. **Validation**:<br>    - Run validation: Zero broken cross-references (all "See Section IV.X" references resolve to existing sections)<br>    - Footnote sequence 1-1423 intact (no duplicates, no gaps)<br>    - Table of Contents section numbers match actual section headers<br>    - CREAC headers present in all 12 analysis sections (36+ structures)<br><br>**Output**: final-memorandum-v2.md | final-memorandum-v2.md | - All 15 integration steps complete<br>- Zero merge conflicts<br>- Zero broken cross-references (validation passed)<br>- Footnote numbering 1-1423 preserved<br>- Table of Contents accurate<br>- CREAC headers in all sections<br>- Cross-references integrated<br>- Counter-analysis consolidated<br>- Document footer present<br>- Ready for QA Pass 2 |
| **W6-002** | (orchestrator invokes memo-qa-diagnostic) | **CRITICAL** | (separate invocation, ~60-90 min) | **Orchestrator to invoke memo-qa-diagnostic for QA Pass 2**<br><br>**Input**: final-memorandum-v2.md<br><br>**Task**: Perform second diagnostic assessment using same 12-dimension framework. Compare scores:<br>- Dimension 0 (Questions Presented): Target 5/5 (up from 0/5)<br>- Dimension 1 (CREAC Structure): Target 10/10 (up from 0/10)<br>- Dimension 3 (Brief Answers): Target 5/5 (up from 2/5)<br>- Dimension 7 (Cross-References): Target 8/8 (up from 3/8)<br>- Other dimensions: Maintain current scores or improve<br><br>**Target Overall Score**: ≥93% (CERTIFY threshold)<br><br>**Output**: qa-outputs/diagnostic-assessment-pass2.md + memo-qa-certifier invocation for certification decision | qa-outputs/diagnostic-assessment-pass2.md<br>+<br>qa-outputs/final-qa-certificate.md | - QA Pass 2 score ≥93%<br>- Zero CRITICAL issues remaining<br>- Zero HIGH issues remaining<br>- ≤2 MEDIUM issues acceptable<br>- Certification decision: CERTIFY or CERTIFY_WITH_LIMITATIONS |

---

## Summary

**Total Tasks**: 36
- Wave 1: 0 tasks (0 hours)
- Wave 2: 2 tasks (6-8 hours)
- Wave 3: 27 tasks (12-16 hours) — 3 P1 (CREAC) + 13 P2 (Cross-Refs) + 13 P3 (Counter-Analysis), hybrid workflow
- Wave 4: 3 tasks (4-6 hours)
- Wave 5: 2 tasks (4-6 hours)
- Wave 6: 2 tasks (3-5 hours)

**Total Duration**: 29-41 hours

**Critical Path**: Wave 2 → Wave 3 (P1 → P2 → P3) → Wave 4 → Wave 5 → Wave 6

**Parallelization Opportunities**:
- Wave 2: W2-001 || W2-002 (parallel)
- Wave 3 P2: W3-XREF-INSERT-IV-A through IV-L (12 parallel tasks)
- Wave 3 P3: W3-COUNTER-IV-A through IV-L (12 parallel tasks)
- Wave 4: W4-001 || W4-002 || W4-003 (parallel)

**Expected Post-Remediation Score**: 93-95% (adds +12 points from Dimensions 0, 1, 3, 7)

**Certification Path**: TIER 3 remediation → QA Pass 2 (≥93%) → CERTIFY

---

**END OF REMEDIATION DISPATCH**
